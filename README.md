# DF-POC-01
Ce PoC a pour but de tester la possibilit√© de traiter une grande quantit√© d'informations avec une configuration locale raisonnable.

Le but global du projet est de construire une application locale qui remplit automatiquement un formulaire PDF √† partir d‚Äôun contexte documentaire (principalement des rapports m√©dicaux). Le contexte peut √™tre volumineux (~80‚Äô000 tokens). L‚Äôapplication doit proposer une extraction fiable, tra√ßable (sources/citations) et produire une sortie exploitable pour remplir le PDF.

Par grande quantit√© d'information, il est entendu un contexte allant jusqu'√† 100k de tokens (en input) avec des performance raisonnnable. Ces performances sont calcul√©es sur le temps de traitement (<5 min), et par le taux de remplissage / la pr√©cision des informations. Ces pr√©cisions ont d'abord √©t√© √©valu√©es @chatgpt/@perplexity (cycle rapide), puis lorsque les r√©sultats ont √©t√© jug√©s comme bons, par des professionnels de la sant√©.  

## Stack utilis√©e

- Hardware : gpu = RTX 4080 SUPER 16Go ; cpu = intel i9-14900k ; ram = 64 Go ; 
- Software : LM Studio 0.3.36
- LLM : [qwen2.5-14b-instruct](https://huggingface.co/Qwen/Qwen2.5-14B-Instruct-GGUF)
- EMBD : text-embedding-nomic-embed-text-v1.5
- Reranking : cross-encoder/ms-marco-MiniLM-L-6-v2
- Language : Python 3.13.5

## Configuration
0) Cr√©er un environnement virtuel python (`python -m venv venv`) et l'activer (macos/linux: `source venv/bin/activate`, win11: `DF-PoC-01\Scripts\activate`)
1) installer le mod√®le (qwen2.5-14b-instruct), puis lancer le serveur LM Studio (https://lmstudio.ai/docs/developer/core/server)
```txt
# configuration du serveur
- contexte mis √† 8192 (au lieu de ~130k)
Le reste est laisser par d√©faut
```
2) Changer la variable `LM_STUDIO_URL` si l'IP et le port ne sont pas : `192.168.1.170:1734`. 
3) Utiliser/cr√©er une template QA (le format est relativement libre, il faut cependant adapter le prompt dans ce cas) et ajouter un contexte (format `.txt`)
4) Changer les variables PATH si n√©cessaire
5) Ex√©uter l'app : `python pipeline.py`

## R√©sultats

### first pass
First pass [commit: 9c817bb0951ad559d7e1ef5baa381223c7de9365] - [doc](tmp/output/resultat_final_v01.json) :
```bash
üìÇ Chargement des donn√©es...
‚úÇÔ∏è  D√©coupage termin√© : 9 documents extraits.
‚è≥ Indexation des documents en cours...
‚úÖ 9 segments index√©s dans ChromaDB.

üöÄ D√©marrage de l'extraction en mode BATCH (77 champs valides)...

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [14:11<00:00, 53.23s/batch]

‚úÖ Extraction termin√©e. 76 champs trait√©s.
üìÅ R√©sultats dans 'resultat_final.json'
```

‚úÖ Extraction termin√©e avec Reranking. 75 champs trait√©s.
```
